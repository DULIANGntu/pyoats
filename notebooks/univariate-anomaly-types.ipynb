{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "628e8b40-08c5-49a7-9048-1108cb23b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fd21ec7-7f01-451c-8875-c0ed6411218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view   \n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75ac4e33-81a1-4792-9705-504ad4867cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from one.generator.univariate import UnivariateDataGenerator\n",
    "from one.models import *\n",
    "from one.utils import *\n",
    "from one.scorer.pot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b8ad3c7-97d8-47a1-bcae-e3aac46138d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0c521f5-f82a-420f-af7a-979c163caf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = 40,10\n",
    "plt.rcParams[\"font.size\"] = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f93de1f-476a-488b-8dd8-9f684364dd57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Generating Univariate Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f468a247-9eca-426b-be62-386bea10d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = UnivariateDataGenerator(stream_length=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbcf757-d9b9-4e0d-a353-46b76ad86c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.collective_seasonal_outliers(0.1, 1., 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c073555c-7f12-4498-91b2-a89904e32b3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72bbafc-c853-43a7-b125-33ddf3da7d12",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c1a18-9035-49f3-ae86-86b1c75d22c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(generator.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e13092-70d0-4740-a991-ccd8965cefb5",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd75a0d-2a5a-4cfb-aad7-36e6366c2f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(2)\n",
    "\n",
    "axes[0].plot(generator.test)\n",
    "axes[1].plot(generator.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f71479-5cd0-4c9b-acb6-0dc2b754c67a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e345e-0eae-4fb7-8aa7-52d169148eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"./data/univar-synth/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f282864-d266-4c1f-b8bd-6b73e011a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point Global\n",
    "out_type = \"point_global\"\n",
    "config_1 = [0.05, 1.1, 50] #ratio, factor, radius\n",
    "config_2 = [0.05, 1.25, 50] #ratio, factor, radius\n",
    "config_3 = [0.05, 1.5, 50] #ratio, factor, radius\n",
    "config_4 = [0.05, 2, 50] #ratio, factor, radius\n",
    "config_5 = [0.05, 3, 50] #ratio, factor, radius\n",
    "\n",
    "for idx, config in enumerate([config_1, config_2, config_3, config_4, config_5]):\n",
    "    generator = UnivariateDataGenerator(stream_length=5000)\n",
    "    generator.point_global_outliers(*config)\n",
    "    \n",
    "    # save train\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-train.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.train)\n",
    "    \n",
    "    # save test\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-test.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.test)\n",
    "    \n",
    "    # save labels\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-labels.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115eee61-0ea2-4913-a446-9bcd3540b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point Contextual\n",
    "out_type = \"point_contextual\"\n",
    "config_1 = [0.05, 1.1, 50] #ratio, factor, radius\n",
    "config_2 = [0.05, 1.25, 50] #ratio, factor, radius\n",
    "config_3 = [0.05, 1.5, 50] #ratio, factor, radius\n",
    "config_4 = [0.05, 2, 50] #ratio, factor, radius\n",
    "config_5 = [0.05, 3, 50] #ratio, factor, radius\n",
    "\n",
    "for idx, config in enumerate([config_1, config_2, config_3, config_4, config_5]):\n",
    "    generator = UnivariateDataGenerator(stream_length=5000)\n",
    "    generator.point_contextual_outliers(*config)\n",
    "    \n",
    "    # save train\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-train.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.train)\n",
    "    \n",
    "    # save test\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-test.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.test)\n",
    "    \n",
    "    # save labels\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-labels.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34ee3c-8adc-4b69-9bad-334aa43779c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collective Global\n",
    "out_type = \"collective_global\"\n",
    "config_1 = [0.05, 50, 1.1] #ratio, radius, coef\n",
    "config_2 = [0.05, 50, 1.25] #ratio, radius, coef\n",
    "config_3 = [0.05, 50, 1.5] #ratio, radius, coef\n",
    "config_4 = [0.05, 50, 2] #ratio, radius, coef\n",
    "config_5 = [0.05, 50, 3] #ratio, radius, coef\n",
    "\n",
    "for idx, config in enumerate([config_1, config_2, config_3, config_4, config_5]):\n",
    "    *args, coef = config\n",
    "    generator = UnivariateDataGenerator(stream_length=5000)\n",
    "    generator.collective_global_outliers(*args, \"square\", coef=coef)\n",
    "    \n",
    "    # save train\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{coef}-train.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.train)\n",
    "    \n",
    "    # save test\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{coef}-test.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.test)\n",
    "    \n",
    "    # save labels\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{coef}-labels.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb5ddd-9060-4310-b6c9-c05b5ba053d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collective Trend\n",
    "out_type = \"collective_trend\"\n",
    "config_1 = [0.05, 0.01, 50] #ratio, factor, radius\n",
    "config_2 = [0.05, 0.02, 50] #ratio, factor, radius\n",
    "config_3 = [0.05, 0.03, 50] #ratio, factor, radius\n",
    "config_4 = [0.05, 0.04, 50] #ratio, factor, radius\n",
    "config_5 = [0.05, 0.05, 50] #ratio, factor, radius\n",
    "\n",
    "for idx, config in enumerate([config_1, config_2, config_3, config_4, config_5]):\n",
    "    generator = UnivariateDataGenerator(stream_length=5000)\n",
    "    generator.collective_trend_outliers(*config)\n",
    "    \n",
    "    # save train\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-train.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.train)\n",
    "    \n",
    "    # save test\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-test.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.test)\n",
    "    \n",
    "    # save labels\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-labels.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4784f76b-664e-45af-8ed6-4a0b51f2395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collective Seasonal\n",
    "out_type = \"collective_seasonal\"\n",
    "config_1 = [0.1, 1.1, 50] #ratio, factor, radius\n",
    "config_2 = [0.1, 1.25, 50] #ratio, factor, radius\n",
    "config_3 = [0.1, 1.5, 50] #ratio, factor, radius\n",
    "config_4 = [0.1, 2, 50] #ratio, factor, radius\n",
    "config_5 = [0.1, 3, 50] #ratio, factor, radius\n",
    "\n",
    "for idx, config in enumerate([config_1, config_2, config_3, config_4, config_5]):\n",
    "    generator = UnivariateDataGenerator(stream_length=5000)\n",
    "    generator.collective_seasonal_outliers(*config)\n",
    "    \n",
    "    # save train\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-train.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.train)\n",
    "    \n",
    "    # save test\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-test.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.test)\n",
    "    \n",
    "    # save labels\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-labels.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c18388-89fa-4954-a693-e7d2ea535038",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Visualize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee03888d-fb73-460d-b742-0b5c1131ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH0 = \"./data/univar-synth/point_global/\"\n",
    "PATH1 = \"./data/univar-synth/point_contextual/\"\n",
    "PATH2 = \"./data/univar-synth/collective_global/\"\n",
    "PATH3 = \"./data/univar-synth/collective_trend/\"\n",
    "PATH4 = \"./data/univar-synth/collective_seasonal/\"\n",
    "PATHS = [PATH0, PATH1, PATH2, PATH3, PATH4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eaef81-87c2-4d5d-949b-c50e6047c63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    \n",
    "    for f in file_list:\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        fig, axes = plt.subplots(2)\n",
    "        axes[0].set_title(f)\n",
    "        axes[0].plot(test)\n",
    "        axes[1].plot(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24463bb6-4cc9-48f4-9b92-5781b967cc1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scoring Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a412f15e-5dd6-404d-b780-1c33747fc427",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreCounter:\n",
    "    def __init__(self):\n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.tn = 0\n",
    "        self.fn = 0\n",
    "        \n",
    "    def process(self, preds, labels):\n",
    "        preds = preds.copy()\n",
    "        labels = labels.copy()\n",
    "        ground_truth_ones = np.where(labels == 1)[0]\n",
    "        pred_ones = np.where(preds == 1)[0]\n",
    "        \n",
    "        ranges = self._consecutive(ground_truth_ones)\n",
    "        \n",
    "        tp, fp, tn, fn = 0, 0, 0, 0\n",
    "        \n",
    "        for r in ranges:\n",
    "            intersect = np.intersect1d(r, pred_ones, assume_unique=True)\n",
    "            if intersect.size != 0:\n",
    "                tp += r.size\n",
    "                preds[intersect] = 0\n",
    "                pred_ones = np.where(preds == 1)[0]\n",
    "            else:\n",
    "                fn += r.size\n",
    "            \n",
    "        fp += pred_ones.size\n",
    "        tn += preds.size - tp - fp - fn\n",
    "        \n",
    "        self.tp += tp\n",
    "        self.fp += fp\n",
    "        self.tn += tn\n",
    "        self.fn += fn\n",
    "        \n",
    "        \n",
    "        return\n",
    "        \n",
    "        \n",
    "    def _consecutive(self, data, stepsize=1):\n",
    "        return np.split(data, np.where(np.diff(data) != stepsize)[0]+1)\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def tpr(self):\n",
    "        return self.tp/(self.fn+self.tp)\n",
    "    \n",
    "    @property\n",
    "    def fpr(self):\n",
    "        return self.fp/(self.tn+self.fp)\n",
    "    \n",
    "    @property\n",
    "    def tnr(self):\n",
    "        return self.tn/(self.tn+self.fp)\n",
    "        \n",
    "    @property\n",
    "    def fnr(self):\n",
    "        return self.fn/(self.fn+self.tp)\n",
    "        \n",
    "    @property\n",
    "    def precision(self):\n",
    "        return self.tp/(self.tp+self.fp)\n",
    "    \n",
    "    @property\n",
    "    def recall(self):\n",
    "        return self.tp/(self.tp+self.fn)\n",
    "    \n",
    "    @property\n",
    "    def f1(self):\n",
    "        if self.precision + self.recall == 0: return 0\n",
    "        return (2*self.precision*self.recall)/(self.precision+self.recall)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568e7322-4b76-4857-9919-230823581a3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b146fb-ea3c-4ffd-8422-e003231a50f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc98de-a929-4f69-a5e8-ea5df3af6e75",
   "metadata": {},
   "source": [
    "### -- Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1da67fb1-f805-446d-9603-5a48486389e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH0 = \"../data/univar-synth/point_global/\"\n",
    "PATH1 = \"../data/univar-synth/point_contextual/\"\n",
    "PATH2 = \"../data/univar-synth/collective_global/\"\n",
    "PATH3 = \"../data/univar-synth/collective_trend/\"\n",
    "PATH4 = \"../data/univar-synth/collective_seasonal/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f027dc8-57c7-4121-b46d-7a083c9a7d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = [PATH0, PATH1, PATH2, PATH3, PATH4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5821ed9e-7c6f-4c78-9491-6164955eadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"../results/univar-synth/untuned/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3766108-92a4-474a-8328-0ccc2849c49e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0885e7b-6ae4-44c7-b90b-b986d281fe7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quantile Model\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        window = 500\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = QuantileModel(window)\n",
    "        scores = model.get_scores(test_extend)[window:] \n",
    "        \n",
    "        save = SAVE_DIR+\"quantile/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"quantile/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", scores)\n",
    "        \n",
    "        scorer.process(scores, labels)\n",
    "       \n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acfef45-99e4-4bca-b4f3-71571b43976b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebba815-e318-470a-8285-2392c6f4b9bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Moving Average Model\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        window = 50\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = MovingAverageModel(window)\n",
    "        scores = model.get_scores(test_extend)[window:] \n",
    "\n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.9)\n",
    "        \n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        save = SAVE_DIR+\"ma/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"ma/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "        \n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd12a5d-a709-44a0-a34d-b54349f7e417",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06feddc6-6f8b-421f-ad67-aedf29538e88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ARIMA\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = ARIMAModel(1,1,1)\n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[window:] \n",
    "\n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.9)\n",
    "        \n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        save = SAVE_DIR+\"arima/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"arima/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "        \n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd31eb5-d1b7-4edb-9328-f7f1c373b9ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### IForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb5077-0bea-4fe7-abf1-96b734beba37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IsolationForest\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        model = IsolationForestModel()\n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test)\n",
    "            \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.9)\n",
    "       \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"iforest/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"iforest/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "       \n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddebc690-57d1-4a4c-84a6-45f396e1bd76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d459aaf-bda0-44bc-a719-aff4ba0e81b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RegressionModel\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        window = 10\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = RegressionModel(window)\n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.90)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"regression/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"regression/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4e33c2-dcac-4e38-8f39-94ce4187e6db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### NBEATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd9f3f8-51a1-4759-ab93-b126bd4fc2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NBEATSModel\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        window = 100\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = NBEATSModel(window, use_gpu=True)\n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.90)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"nbeats/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"nbeats/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a59d3f-ecbb-43a3-9e09-e3ccfccac1ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### NHiTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d60e31-4940-443a-9779-23c1d3931199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        window = 100\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = NHiTSModel(window, use_gpu=True)\n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.90)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"nhits/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"nhits/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4193f0-42c3-4547-b5d5-b63b9e79629c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### RNN(GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7781c98b-9659-40ec-a422-fec5c723e370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        window = 100\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = RNNModel(window, use_gpu=True, rnn_model=\"GRU\")\n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.90)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"rnn_gru/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"rnn_gru/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a47e38-bf4c-4e87-8b95-e47fc09a6198",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac05b28-b54f-4839-934a-45d157fa24b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        window = 100\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = TCNModel(window, use_gpu=True)\n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.90)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"tcn/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"tcn/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d59388f-b803-4b0f-bf6d-7092436b7cab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3398f606-4124-458e-a45c-91af8f5f8a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        window = 100\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = TransformerModel(window, use_gpu=True)\n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.90)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"transformer/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"transformer/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde26581-83e8-4c5f-a4b0-009307d1783c",
   "metadata": {},
   "source": [
    "### TranAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "326e7ce8-c1ea-49de-a690-add7818979f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115, 1904, 17124, 857, 0.1183127572016461, 0.10006306495690562, 0.8999369350430944, 0.8816872427983539, 0.05695889053987122, 0.1183127572016461, 0.07689735874289534\n",
      "106, 1894, 17127, 873, 0.10827374872318693, 0.09957415488144682, 0.9004258451185532, 0.891726251276813, 0.053, 0.10827374872318693, 0.0711648204095334\n",
      "600, 1770, 17230, 400, 0.6, 0.0931578947368421, 0.9068421052631579, 0.4, 0.25316455696202533, 0.6, 0.3560830860534125\n",
      "404, 1883, 17213, 500, 0.4469026548672566, 0.09860703812316715, 0.9013929618768328, 0.5530973451327433, 0.17665063401836467, 0.4469026548672566, 0.2532121591977437\n",
      "1871, 1808, 16321, 0, 1.0, 0.09972971482155663, 0.9002702851784434, 0.0, 0.5085621092688231, 1.0, 0.6742342342342342\n"
     ]
    }
   ],
   "source": [
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        window = 100\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = TranADModel(window, use_gpu=True)\n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[window:]\n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.90)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"tranad/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"tranad/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d877e11c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## F1 Tuned - 100% dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a158fb7d",
   "metadata": {},
   "source": [
    "### -- Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1243af",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH0 = \"./data/univar-synth/point_global/\"\n",
    "PATH1 = \"./data/univar-synth/point_contextual/\"\n",
    "PATH2 = \"./data/univar-synth/collective_global/\"\n",
    "PATH3 = \"./data/univar-synth/collective_trend/\"\n",
    "PATH4 = \"./data/univar-synth/collective_seasonal/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62953687",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = [PATH0, PATH1, PATH2, PATH3, PATH4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a5b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"./results/univar-synth/f1tuned-100pct/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace353be",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.FATAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bcb180",
   "metadata": {},
   "source": [
    "### Quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070298a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quantile Model\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            window = trial.suggest_int(\"window\", 100, 1000)\n",
    "            threshold = trial.suggest_float(\"threshold\", 0.95, 0.999)\n",
    "            \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "            model = QuantileModel(window)\n",
    "            scores = model.get_scores(test_extend)[window:] \n",
    "            \n",
    "\n",
    "            s.process(preds, labels)\n",
    "       \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            return s.f1\n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=150)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        threshold = study.best_params[\"threshold\"]\n",
    "        model = QuantileModel(window, threshold)\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        \n",
    "        scores = model.get_scores(test_extend)[window:] \n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"quantile/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"quantile/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", scores)\n",
    "\n",
    "        scorer.process(scores, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66ecbf",
   "metadata": {},
   "source": [
    "### MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295cf97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MA Model \n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "            model = MovingAverageModel(window)\n",
    "            scores = np.abs(model.get_scores(test_extend)[window:])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            return s.f1\n",
    "            \n",
    "       \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=150)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        model = MovingAverageModel(window)\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        \n",
    "        scores = np.abs(model.get_scores(test_extend)[window:] )\n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"ma/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"ma/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40acc764",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b27b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA Model \n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            p = trial.suggest_int(\"p\", 1, 20)\n",
    "            d = trial.suggest_int(\"d\", 0, 3)\n",
    "            q = trial.suggest_int(\"q\", 0, 20)\n",
    "            q_risk = trial.suggest_float(\"q_risk\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    " \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "                \n",
    "            model = ARIMAModel(p, d, q)\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend))\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q_risk, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "       \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=20)\n",
    "       \n",
    "        p = study.best_params[\"p\"]\n",
    "        d = study.best_params[\"d\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        q_risk = study.best_params[\"q_risk\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "        model = ARIMAModel(p, d, q)\n",
    "        model.fit(train)\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        scores = np.abs(model.get_scores(test_extend))\n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q_risk, contam)\n",
    "        \n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"arima/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"arima/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa95cdb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### IForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2439bb99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IForest Model \n",
    "import warnings\n",
    "warnings.filterwarnings('error')\n",
    "\n",
    "\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "                \n",
    "            model = IsolationForestModel()\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test))\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            \n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "            \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=150)\n",
    "       \n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        model = IsolationForestModel()\n",
    "        model.fit(train)\n",
    "        scores = np.abs(model.get_scores(test))\n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"iforest/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"iforest/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9765ec1b",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f08b776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Regression Model \n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            lags = trial.suggest_int(\"lags\", 1, 5)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    " \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "                \n",
    "            model = RegressionModel(window, n_steps, lags)\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "       \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=50)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        lags = study.best_params[\"lags\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "        model = RegressionModel(window,n_steps, lags)\n",
    "        model.fit(train)\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        scores = np.abs(model.get_scores(test_extend)[0])\n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"regression/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"regression/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cef4025",
   "metadata": {},
   "source": [
    "### NBEATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8866c5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# NBEATSModel\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "#             params = {\n",
    "#              \"num_blocks\": trial.suggest_int(\"num_blocks\", 1, 2),\n",
    "#              \"num_stacks\": trial.suggest_int(\"num_stacks\", 2, 32),\n",
    "#              \"num_layers\": trial.suggest_int(\"num_layers\", 1, 16),\n",
    "#              \"layer_widths\": trial.suggest_int(\"layer_widths\", 128, 512),\n",
    "#              \"expansion_coefficient_dim\": trial.suggest_int(\n",
    "#                  \"expansion_coefficient_dim\", 1, 10\n",
    "#              ),\n",
    "#             } \n",
    " \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "                \n",
    "            model = NBEATSModel(window, n_steps, use_gpu=True)            \n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "#         params = {\n",
    "#          \"num_blocks\": study.best_params[\"num_blocks\"],\n",
    "#          \"num_stacks\": study.best_params[\"num_stacks\"],\n",
    "#          \"num_layers\": study.best_params[\"num_layers\"],\n",
    "#          \"layer_widths\": study.best_params[\"layer_widths\"],\n",
    "#          \"expansion_coefficient_dim\": study.best_params[\"expansion_coefficient_dim\"],\n",
    "#         } \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = NBEATSModel(window, n_steps, use_gpu=True)\n",
    "#         model.params = params\n",
    "#         model._init_model(**model.params)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"nbeats/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"nbeats/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"nbeats/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99be305c",
   "metadata": {},
   "source": [
    "### NHiTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d803257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture #supress output\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "                \n",
    "            model = NHiTSModel(window, n_steps, use_gpu=True)\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = NHiTSModel(window, n_steps, use_gpu=True)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"nhits/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"nhits/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"nhits/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52cd792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in PATHS:\n",
    "#     scorer = ScoreCounter()\n",
    "#     file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "#     for f in file_list:\n",
    "#         labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "#         preds = np.loadtxt(SAVE_DIR+\"nhits/\"+f+\"-preds.txt\")\n",
    "#         scorer.process(preds, labels)\n",
    "        \n",
    "#     print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb85e191",
   "metadata": {},
   "source": [
    "### RNN(GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055223b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#supress output\n",
    "\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "#             params = {\n",
    "#              \"hidden_dim\": trial.suggest_int(\"hidden_dim\", 10, 256),\n",
    "#              \"n_rnn_layers\": trial.suggest_int(\"n_rnn_layers\", 1, 64),\n",
    "#              \"dropout\": trial.suggest_float(\"dropout\", 0.0, 0.3),\n",
    "#              } \n",
    " \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "                \n",
    "            model = RNNModel(window, n_steps, rnn_model=\"GRU\")\n",
    "#             model.params = params\n",
    "#             model._init_model(**model.params)\n",
    "            \n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "#         params = {\n",
    "#          \"hidden_dim\": study.best_params[\"hidden_dim\"],\n",
    "#          \"n_rnn_layers\": study.best_params[\"n_rnn_layers\"],\n",
    "#          \"dropout\": study.best_params[\"dropout\"],\n",
    "#         } \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = RNNModel(window, n_steps, use_gpu=True, rnn_model=\"GRU\")\n",
    "#         model.params = params\n",
    "#         model._init_model(**model.params)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"rnn_gru/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"rnn_gru/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"rnn_gru/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63b4567",
   "metadata": {},
   "source": [
    "### TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0173ab58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#supress output\n",
    "# %%capture\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "#             params = {\n",
    "#              \"kernel_size\": trial.suggest_int(\n",
    "#                  \"kernel_size\", 2, min(32, window - 1)\n",
    "#              ),\n",
    "#              \"num_filters\": trial.suggest_int(\"num_filters\", 2, 8),\n",
    "#              \"weight_norm\": trial.suggest_categorical(\"weight_norm\", [True, False]),\n",
    "#              \"dilation_base\": trial.suggest_int(\"dilation_base\", 1, 4),\n",
    "#              \"dropout\": trial.suggest_float(\"dropout\", 0.0, 0.3),\n",
    "#              }\n",
    "                \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "            \n",
    "            model = TCNModel(window, n_steps, use_gpu=True)\n",
    "            #model.params = params\n",
    "            #model._init_model(**model.params)\n",
    "            \n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "#         params = {\n",
    "#          \"kernel_size\": study.best_params[\"kernel_size\"],\n",
    "#          \"num_filters\": study.best_params[\"num_filters\"],\n",
    "#          \"dilation_base\": study.best_params[\"dilation_base\"],\n",
    "#          \"dropout\": study.best_params[\"dropout\"],\n",
    "#         } \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = TCNModel(window, n_steps, use_gpu=True)\n",
    "#         model.params = params\n",
    "#         model._init_model(**model.params)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"tcn/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"tcn/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"tcn/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d30be85",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cc5af1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "                \n",
    "            model = TransformerModel(window, n_steps, use_gpu=True)\n",
    "            %%capture #supress output\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = TransformerModel(window, n_steps, use_gpu=True)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"transformer/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"transformer/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"transformer/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40343d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in PATHS:\n",
    "    scorer = ScoreCounter()\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    for f in file_list:\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        preds = np.loadtxt(SAVE_DIR+\"transformer/\"+f+\"-preds.txt\")\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c8acc2-00db-4d94-bf16-a63d22043a7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## F1 Tuned - 50% dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65a3c1e-7a7f-4cf2-a2bb-e596baa6f8d3",
   "metadata": {},
   "source": [
    "### -- Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ef0fb3f4-9acd-4b99-94a9-9068c8ef2601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from one.models import *\n",
    "from one.utils import *\n",
    "from one.scorer.pot import *\n",
    "from numpy.lib.stride_tricks import sliding_window_view   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "424b29d3-c4a0-4d09-83f0-904dce2ed7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH0 = \"../data/univar-synth/point_global/\"\n",
    "PATH1 = \"../data/univar-synth/point_contextual/\"\n",
    "PATH2 = \"../data/univar-synth/collective_global/\"\n",
    "PATH3 = \"../data/univar-synth/collective_trend/\"\n",
    "PATH4 = \"../data/univar-synth/collective_seasonal/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7509bfcb-ac94-4ff9-a492-ae5609d53aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = [PATH0, PATH1, PATH2, PATH3, PATH4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "986822e6-c5e0-482f-b200-27f4fa17ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"../results/univar-synth/f1tuned-50pct/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "51bd02e3-2b7d-41da-8ca6-f8ca5dacd656",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d5eea4-7ba6-41d0-8e29-a8b0a1402de3",
   "metadata": {},
   "source": [
    "### Quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b615cff-4baf-43cf-9e71-f07a21b715fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quantile Model\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "        test_data, t4est_labels = test[n_tune:], labels[n_tune:]\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            window = trial.suggest_int(\"window\", 100, 1000)\n",
    "            threshold = trial.suggest_float(\"threshold\", 0.95, 0.999)\n",
    "            \n",
    "            test_extend = np.concatenate((train[-window:], tune_data))\n",
    "            model = QuantileModel(window)\n",
    "            scores = model.get_scores(test_extend)[window:] \n",
    "            \n",
    "\n",
    "            s.process(preds, tune_labels)\n",
    "       \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            return s.f1\n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=150)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        threshold = study.best_params[\"threshold\"]\n",
    "        model = QuantileModel(window, threshold)\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        \n",
    "        scores = model.get_scores(test_extend)[window:] \n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"quantile/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"quantile/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", scores)\n",
    "\n",
    "        scorer.process(scores, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35090c0b-683d-41f0-bcac-0955143aabe2",
   "metadata": {},
   "source": [
    "### MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1c514753-fcd2-4983-bac6-69daabf7610f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402, 26, 9484, 88, 0.8204081632653061, 0.002733964248159832, 0.9972660357518401, 0.17959183673469387, 0.9392523364485982, 0.8204081632653061, 0.8758169934640523\n",
      "28, 237, 9289, 446, 0.05907172995780591, 0.024879277766113792, 0.9751207222338862, 0.9409282700421941, 0.10566037735849057, 0.05907172995780591, 0.07577807848443843\n",
      "200, 16, 9484, 300, 0.4, 0.0016842105263157896, 0.9983157894736842, 0.6, 0.9259259259259259, 0.4, 0.558659217877095\n",
      "200, 8, 9792, 0, 1.0, 0.0008163265306122449, 0.9991836734693877, 0.0, 0.9615384615384616, 1.0, 0.9803921568627451\n",
      "667, 78, 9155, 100, 0.8696219035202086, 0.008447958410050905, 0.9915520415899491, 0.1303780964797914, 0.8953020134228188, 0.8696219035202086, 0.8822751322751323\n"
     ]
    }
   ],
   "source": [
    "# MA Model \n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "        test_data, test_labels = test[n_tune:], labels[n_tune:]\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            contam = trial.suggest_float(\"level\", 0.90, 0.999)\n",
    "            \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "            model = MovingAverageModel(window)\n",
    "            scores = np.abs(model.get_scores(test_extend)[window:])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = np.quantile(scores, contam)\n",
    "            \n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            return s.f1\n",
    "            \n",
    "       \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=50)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        contam = study.best_params[\"level\"]\n",
    "        model = MovingAverageModel(window)\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        \n",
    "        scores = np.abs(model.get_scores(test_extend)[window:] )\n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = np.quantile(scores[:n_tune], contam)\n",
    "        preds = scores[n_tune:].copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "\n",
    "        scorer.process(preds, labels[n_tune:])\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"ma/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"ma/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores[n_tune:], header=str(study.best_params))\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=str(study.best_params))\n",
    "\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c1fc97-dd42-4b80-af36-4d7965d64c21",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cecc21-3402-4857-b815-fcd5bbc8a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA Model \n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "\n",
    "\n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            p = trial.suggest_int(\"p\", 1, 20)\n",
    "            d = trial.suggest_int(\"d\", 0, 3)\n",
    "            q = trial.suggest_int(\"q\", 0, 20)\n",
    "            q_risk = trial.suggest_float(\"q_risk\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    " \n",
    "            test_extend = np.concatenate((train[-window:], tune_data))\n",
    "                \n",
    "            model = ARIMAModel(p, d, q)\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend))\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q_risk, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "       \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=20)\n",
    "       \n",
    "        p = study.best_params[\"p\"]\n",
    "        d = study.best_params[\"d\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        q_risk = study.best_params[\"q_risk\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "        model = ARIMAModel(p, d, q)\n",
    "        model.fit(train)\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        scores = np.abs(model.get_scores(test_extend))\n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q_risk, contam)\n",
    "        \n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"arima/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"arima/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6152b849-782e-45ae-8793-b36e8c17b60c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### IForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec0b52a-f461-476e-a906-a18e5e45155f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IForest Model \n",
    "import warnings\n",
    "warnings.filterwarnings('error')\n",
    "\n",
    "\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "\n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "                \n",
    "            model = IsolationForestModel()\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(tune_data))\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = np.quantile(scores, contam)\n",
    "            \n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "            \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=150)\n",
    "       \n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        model = IsolationForestModel()\n",
    "        model.fit(train)\n",
    "        scores = np.abs(model.get_scores(test))\n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"iforest/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"iforest/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dce11d2-6d48-49b0-9b45-407e5e9ee150",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "45b2c35c-0a5b-460c-9106-972e95ba8e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342, 142, 9368, 148, 0.6979591836734694, 0.014931650893796004, 0.985068349106204, 0.3020408163265306, 0.7066115702479339, 0.6979591836734694, 0.7022587268993841\n",
      "271, 300, 9226, 203, 0.5717299578059072, 0.03149275666596683, 0.9685072433340332, 0.4282700421940928, 0.4746059544658494, 0.5717299578059072, 0.5186602870813397\n",
      "500, 3, 9497, 0, 1.0, 0.00031578947368421053, 0.9996842105263158, 0.0, 0.9940357852882704, 1.0, 0.9970089730807578\n",
      "100, 464, 9336, 100, 0.5, 0.0473469387755102, 0.9526530612244898, 0.5, 0.1773049645390071, 0.5, 0.2617801047120419\n",
      "767, 36, 9197, 0, 1.0, 0.003899057727715802, 0.9961009422722842, 0.0, 0.9551681195516812, 1.0, 0.9770700636942675\n"
     ]
    }
   ],
   "source": [
    "# Regression Model \n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "\n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            lags = trial.suggest_int(\"lags\", 1, 5)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    " \n",
    "            test_extend = np.concatenate((train[-window:], tune_data))\n",
    "                \n",
    "            model = RegressionModel(window, n_steps, lags)\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = np.quantile(scores, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "       \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=10)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        lags = study.best_params[\"lags\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "        model = RegressionModel(window, n_steps, lags)\n",
    "        model.fit(train)\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        scores = np.abs(model.get_scores(test_extend)[0])\n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = np.quantile(scores[n_tune:], contam)\n",
    "        \n",
    "        preds = scores[n_tune:].copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "\n",
    "        scorer.process(preds, labels[n_tune:])\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"regression/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"regression/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores[n_tune:], header=str(study.best_params))\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=str(study.best_params))\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a695b8-f6e2-4349-9b4a-1a104ab927d0",
   "metadata": {},
   "source": [
    "### NBEATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103a7312-9fa6-4e97-9814-9411e1c669ac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# NBEATSModel\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "#             params = {\n",
    "#              \"num_blocks\": trial.suggest_int(\"num_blocks\", 1, 2),\n",
    "#              \"num_stacks\": trial.suggest_int(\"num_stacks\", 2, 32),\n",
    "#              \"num_layers\": trial.suggest_int(\"num_layers\", 1, 16),\n",
    "#              \"layer_widths\": trial.suggest_int(\"layer_widths\", 128, 512),\n",
    "#              \"expansion_coefficient_dim\": trial.suggest_int(\n",
    "#                  \"expansion_coefficient_dim\", 1, 10\n",
    "#              ),\n",
    "#             } \n",
    " \n",
    "            test_extend = np.concatenate((train[-window:], tune_data))\n",
    "                \n",
    "            model = NBEATSModel(window, n_steps, use_gpu=True)            \n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "#         params = {\n",
    "#          \"num_blocks\": study.best_params[\"num_blocks\"],\n",
    "#          \"num_stacks\": study.best_params[\"num_stacks\"],\n",
    "#          \"num_layers\": study.best_params[\"num_layers\"],\n",
    "#          \"layer_widths\": study.best_params[\"layer_widths\"],\n",
    "#          \"expansion_coefficient_dim\": study.best_params[\"expansion_coefficient_dim\"],\n",
    "#         } \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = NBEATSModel(window, n_steps, use_gpu=True)\n",
    "#         model.params = params\n",
    "#         model._init_model(**model.params)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"nbeats/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"nbeats/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"nbeats/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d3dd36-c4cd-42b3-abf5-c8f4aaf23b92",
   "metadata": {},
   "source": [
    "### NHiTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3278ef0-881b-446b-afa5-b148345df8c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#supress output\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        \n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "\n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "            test_extend = np.concatenate((train[-window:], tune_data))\n",
    "                \n",
    "            model = NHiTSModel(window, n_steps, use_gpu=True)\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = NHiTSModel(window, n_steps, use_gpu=True)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"nhits/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"nhits/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"nhits/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d84b0d1-d9d5-4e95-b35c-b3d8cd53e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in PATHS:\n",
    "#     scorer = ScoreCounter()\n",
    "#     file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "#     for f in file_list:\n",
    "#         labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "#         preds = np.loadtxt(SAVE_DIR+\"nhits/\"+f+\"-preds.txt\")\n",
    "#         scorer.process(preds, labels)\n",
    "        \n",
    "#     print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d6373-721d-4087-894d-2eed122a8d98",
   "metadata": {},
   "source": [
    "### RNN(GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa60b5-0d53-45a9-b0e2-fb7d85434552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#supress output\n",
    "\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "#             params = {\n",
    "#              \"hidden_dim\": trial.suggest_int(\"hidden_dim\", 10, 256),\n",
    "#              \"n_rnn_layers\": trial.suggest_int(\"n_rnn_layers\", 1, 64),\n",
    "#              \"dropout\": trial.suggest_float(\"dropout\", 0.0, 0.3),\n",
    "#              } \n",
    " \n",
    "            test_extend = np.concatenate((train[-window:], tune_data))\n",
    "                \n",
    "            model = RNNModel(window, n_steps, rnn_model=\"GRU\")\n",
    "#             model.params = params\n",
    "#             model._init_model(**model.params)\n",
    "            \n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "#         params = {\n",
    "#          \"hidden_dim\": study.best_params[\"hidden_dim\"],\n",
    "#          \"n_rnn_layers\": study.best_params[\"n_rnn_layers\"],\n",
    "#          \"dropout\": study.best_params[\"dropout\"],\n",
    "#         } \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = RNNModel(window, n_steps, use_gpu=True, rnn_model=\"GRU\")\n",
    "#         model.params = params\n",
    "#         model._init_model(**model.params)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"rnn_gru/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"rnn_gru/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"rnn_gru/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b1b76e-9ba3-47ef-8f52-abe62d222746",
   "metadata": {},
   "source": [
    "### TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476829ed-51d3-4414-80a2-b7e1f1ae93d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 9, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "#             params = {\n",
    "#              \"kernel_size\": trial.suggest_int(\n",
    "#                  \"kernel_size\", 2, min(32, window - 1)\n",
    "#              ),\n",
    "#              \"num_filters\": trial.suggest_int(\"num_filters\", 2, 8),\n",
    "#              \"weight_norm\": trial.suggest_categorical(\"weight_norm\", [True, False]),\n",
    "#              \"dilation_base\": trial.suggest_int(\"dilation_base\", 1, 4),\n",
    "#              \"dropout\": trial.suggest_float(\"dropout\", 0.0, 0.3),\n",
    "#              }\n",
    "                \n",
    "            test_extend = np.concatenate((train[-window:], tune_data))\n",
    "            \n",
    "            model = TCNModel(window, n_steps, use_gpu=True)\n",
    "            #model.params = params\n",
    "            #model._init_model(**model.params)\n",
    "            \n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "#         params = {\n",
    "#          \"kernel_size\": study.best_params[\"kernel_size\"],\n",
    "#          \"num_filters\": study.best_params[\"num_filters\"],\n",
    "#          \"dilation_base\": study.best_params[\"dilation_base\"],\n",
    "#          \"dropout\": study.best_params[\"dropout\"],\n",
    "#         } \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = TCNModel(window, n_steps, use_gpu=True)\n",
    "#         model.params = params\n",
    "#         model._init_model(**model.params)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"tcn/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"tcn/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"tcn/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baa0482-d0bd-4718-98e0-0eb6f9c9678e",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb8a6a3-0cba-403b-b175-2e56002696e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "            test_extend = np.concatenate((train[-window:], tune_data))\n",
    "                \n",
    "            model = TransformerModel(window, n_steps, use_gpu=True)\n",
    "\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = TransformerModel(window, n_steps, use_gpu=True)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"transformer/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"transformer/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"transformer/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c051f-6787-4d28-baea-d1849b63a651",
   "metadata": {},
   "source": [
    "## Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d52c6679-4a62-4f35-b44e-65a9f8a6358a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165, 23, 9487, 325, 0.336734693877551, 0.00241850683491062, 0.9975814931650894, 0.6632653061224489, 0.8776595744680851, 0.336734693877551, 0.48672566371681414\n",
      "19, 203, 9323, 455, 0.04008438818565401, 0.02131009867730422, 0.9786899013226957, 0.959915611814346, 0.08558558558558559, 0.04008438818565401, 0.0545977011494253\n",
      "200, 194, 9306, 300, 0.4, 0.020421052631578947, 0.9795789473684211, 0.6, 0.5076142131979695, 0.4, 0.44742729306487694\n",
      "100, 271, 9529, 100, 0.5, 0.027653061224489794, 0.9723469387755102, 0.5, 0.2695417789757412, 0.5, 0.350262697022767\n",
      "667, 197, 9036, 100, 0.8696219035202086, 0.021336510343333694, 0.9786634896566663, 0.1303780964797914, 0.7719907407407407, 0.8696219035202086, 0.8179031269160024\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = \"../results/univar-synth/untuned/\"\n",
    "model = \"quantile\"\n",
    "for path in PATHS:\n",
    "    scorer = ScoreCounter()\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    for f in file_list:\n",
    "        preds = np.loadtxt(SAVE_DIR+f\"{model}/\"+f+\"-preds.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")[-len(preds):]\n",
    "        if len(preds) != 2000: break\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3d810f46-7a04-4280-866c-4b4e7b680309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d25edd0-ae2d-4759-a700-c154a969ff54",
   "metadata": {},
   "source": [
    "# Fix Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc030bf5-2b68-4b1f-af47-9e54b06ba478",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH0 = \"../data/univar-synth/point_global/\"\n",
    "PATH1 = \"../data/univar-synth/point_contextual/\"\n",
    "PATH2 = \"../data/univar-synth/collective_global/\"\n",
    "PATH3 = \"../data/univar-synth/collective_trend/\"\n",
    "PATH4 = \"../data/univar-synth/collective_seasonal/\"\n",
    "\n",
    "PATHS = [PATH0, PATH1, PATH2, PATH3, PATH4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "74651351-cc11-48ae-944d-875ecb83fba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163, 68, 9442, 327, 0.3326530612244898, 0.007150368033648791, 0.9928496319663512, 0.6673469387755102, 0.7056277056277056, 0.3326530612244898, 0.4521497919556172\n",
      "22, 363, 9163, 452, 0.046413502109704644, 0.03810623556581986, 0.9618937644341802, 0.9535864978902954, 0.05714285714285714, 0.046413502109704644, 0.051222351571594875\n",
      "200, 200, 9300, 300, 0.4, 0.021052631578947368, 0.9789473684210527, 0.6, 0.5, 0.4, 0.4444444444444445\n",
      "200, 170, 9630, 0, 1.0, 0.017346938775510204, 0.9826530612244898, 0.0, 0.5405405405405406, 1.0, 0.7017543859649124\n",
      "767, 182, 9051, 0, 1.0, 0.019711902956785442, 0.9802880970432145, 0.0, 0.8082191780821918, 1.0, 0.8939393939393939\n"
     ]
    }
   ],
   "source": [
    "# Untuned\n",
    "SAVE_DIR = \"../results/univar-synth/f1tuned-100pct/\"\n",
    "model = \"quantile\"\n",
    "\n",
    "############################\n",
    "\n",
    "for path in PATHS:\n",
    "    scorer = ScoreCounter()\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    for f in file_list:\n",
    "        save = SAVE_DIR+f\"{model}/\"+f\n",
    "        \n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        n_tune = labels.size // 2\n",
    "        \n",
    "        labels = labels[n_tune:]\n",
    "        scores_test = np.loadtxt(SAVE_DIR+f\"{model}/\"+f+\"-scores.txt\")[n_tune:]\n",
    "        preds_test = np.loadtxt(SAVE_DIR+f\"{model}/\"+f+\"-preds.txt\")[n_tune:]\n",
    "        \n",
    "        scorer.process(preds_test, labels)\n",
    "        \n",
    "        np.savetxt(save+\"-scores.txt\", scores_test)\n",
    "        np.savetxt(save+\"-preds.txt\", preds_test)\n",
    "\n",
    "        \n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "df31a173-5cb0-4481-a8e2-f9a1f05b9cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351, 677, 8833, 139, 0.7163265306122449, 0.07118822292323869, 0.9288117770767613, 0.2836734693877551, 0.3414396887159533, 0.7163265306122449, 0.4624505928853755\n",
      "72, 940, 8586, 402, 0.1518987341772152, 0.09867730422002939, 0.9013226957799706, 0.8481012658227848, 0.07114624505928854, 0.1518987341772152, 0.09690444145356662\n",
      "500, 659, 8841, 0, 1.0, 0.06936842105263158, 0.9306315789473685, 0.0, 0.4314063848144953, 1.0, 0.6027727546714888\n",
      "100, 2402, 7398, 100, 0.5, 0.24510204081632653, 0.7548979591836734, 0.5, 0.03996802557953637, 0.5, 0.07401924500370095\n",
      "667, 808, 8425, 100, 0.8696219035202086, 0.08751218455539911, 0.9124878154446009, 0.1303780964797914, 0.45220338983050845, 0.8696219035202086, 0.5950044603033007\n"
     ]
    }
   ],
   "source": [
    "# Untuned\n",
    "SAVE_DIR = \"../results/univar-synth/untuned/\"\n",
    "model = \"quantile\"\n",
    "\n",
    "############################\n",
    "\n",
    "for path in PATHS:\n",
    "    scorer = ScoreCounter()\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    for f in file_list:\n",
    "        save = SAVE_DIR+f\"{model}/\"+f\n",
    "        \n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        n_tune = labels.size // 2\n",
    "        \n",
    "        labels = labels[n_tune:]\n",
    "        scores_val = np.loadtxt(SAVE_DIR+f\"{model}/\"+f+\"-scores.txt\")[:n_tune]\n",
    "        scores_test = np.loadtxt(SAVE_DIR+f\"{model}/\"+f+\"-scores.txt\")[n_tune:]\n",
    "        \n",
    "        thres = pot(scores_val, 1e-1, 0.9)\n",
    "        \n",
    "        preds = scores_test.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "        np.savetxt(save+\"-scores.txt\", scores_test, header=str({\"thres\": thres}))\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=str({\"thres\": thres}))\n",
    "\n",
    "        \n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b54501e5-0ea8-46ec-8080-b3771d34094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473, 0, 9510, 17, 0.9653061224489796, 0.0, 1.0, 0.03469387755102041, 1.0, 0.9653061224489796, 0.9823468328141225\n",
      "301, 62, 9464, 173, 0.6350210970464135, 0.006508503044299811, 0.9934914969557002, 0.3649789029535865, 0.8292011019283747, 0.6350210970464135, 0.7192353643966548\n",
      "500, 0, 9500, 0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0\n",
      "200, 1342, 8458, 0, 1.0, 0.13693877551020409, 0.8630612244897959, 0.0, 0.1297016861219196, 1.0, 0.22962112514351324\n",
      "767, 38, 9195, 0, 1.0, 0.0041156720459222355, 0.9958843279540778, 0.0, 0.9527950310559006, 1.0, 0.9758269720101781\n"
     ]
    }
   ],
   "source": [
    "# Tuned\n",
    "import json\n",
    "from scipy import stats\n",
    "\n",
    "SAVE_DIR = \"../results/univar-synth/f1tuned-50pct/\"\n",
    "model = \"nbeats\"\n",
    "\n",
    "############################\n",
    "\n",
    "for path in PATHS:\n",
    "    scorer = ScoreCounter()\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    for f in file_list:\n",
    "        save = SAVE_DIR+f\"{model}/\"+f\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        n_tune = labels.size // 2\n",
    "        \n",
    "        labels = labels[n_tune:]\n",
    "        scores = np.loadtxt(SAVE_DIR+f\"{model}/\"+f+\"-scores.txt\")\n",
    "        scores_val = np.loadtxt(SAVE_DIR+f\"{model}/\"+f+\"-scores.txt\")[:n_tune]\n",
    "        scores_test = np.loadtxt(SAVE_DIR+f\"{model}/\"+f+\"-scores.txt\")[n_tune:]\n",
    "        \n",
    "        with open(SAVE_DIR+f\"{model}/\"+f+\"-preds.txt\") as f:\n",
    "            params = f.readline()\n",
    "            \n",
    "        if \"#\" not in params: print(\"need to be redone\"); break\n",
    "        \n",
    "        params = params.replace(\"# \", \"\")\n",
    "        params = params.replace(\"'\", '\"')\n",
    "        params = json.loads(params)\n",
    "        thres = pot(scores_val, params[\"q\"], params[\"contam\"])\n",
    "        \n",
    "        params.update({\"thres\": thres})\n",
    "        \n",
    "        preds = scores_test.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1       \n",
    "        \n",
    "        np.savetxt(save+\"-scores.txt\", scores_test, header=str(params))\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=str(params))\n",
    "\n",
    "        \n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a47f9-c1df-472f-96ac-d8038c4ec72d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
