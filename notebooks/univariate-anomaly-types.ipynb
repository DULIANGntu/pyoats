{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628e8b40-08c5-49a7-9048-1108cb23b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd21ec7-7f01-451c-8875-c0ed6411218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view   \n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac4e33-81a1-4792-9705-504ad4867cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from one.generator.univariate import UnivariateDataGenerator\n",
    "from one.models import *\n",
    "from one.utils import *\n",
    "from one.scorer.pot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ad3c7-97d8-47a1-bcae-e3aac46138d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c521f5-f82a-420f-af7a-979c163caf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = 40,10\n",
    "plt.rcParams[\"font.size\"] = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f93de1f-476a-488b-8dd8-9f684364dd57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Generating Univariate Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f468a247-9eca-426b-be62-386bea10d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = UnivariateDataGenerator(stream_length=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbcf757-d9b9-4e0d-a353-46b76ad86c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.collective_seasonal_outliers(0.1, 1., 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c073555c-7f12-4498-91b2-a89904e32b3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72bbafc-c853-43a7-b125-33ddf3da7d12",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c1a18-9035-49f3-ae86-86b1c75d22c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(generator.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e13092-70d0-4740-a991-ccd8965cefb5",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd75a0d-2a5a-4cfb-aad7-36e6366c2f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(2)\n",
    "\n",
    "axes[0].plot(generator.test)\n",
    "axes[1].plot(generator.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f71479-5cd0-4c9b-acb6-0dc2b754c67a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e345e-0eae-4fb7-8aa7-52d169148eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"./data/univar-synth/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f282864-d266-4c1f-b8bd-6b73e011a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point Global\n",
    "out_type = \"point_global\"\n",
    "config_1 = [0.05, 1.1, 50] #ratio, factor, radius\n",
    "config_2 = [0.05, 1.25, 50] #ratio, factor, radius\n",
    "config_3 = [0.05, 1.5, 50] #ratio, factor, radius\n",
    "config_4 = [0.05, 2, 50] #ratio, factor, radius\n",
    "config_5 = [0.05, 3, 50] #ratio, factor, radius\n",
    "\n",
    "for idx, config in enumerate([config_1, config_2, config_3, config_4, config_5]):\n",
    "    generator = UnivariateDataGenerator(stream_length=5000)\n",
    "    generator.point_global_outliers(*config)\n",
    "    \n",
    "    # save train\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-train.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.train)\n",
    "    \n",
    "    # save test\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-test.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.test)\n",
    "    \n",
    "    # save labels\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-labels.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115eee61-0ea2-4913-a446-9bcd3540b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point Contextual\n",
    "out_type = \"point_contextual\"\n",
    "config_1 = [0.05, 1.1, 50] #ratio, factor, radius\n",
    "config_2 = [0.05, 1.25, 50] #ratio, factor, radius\n",
    "config_3 = [0.05, 1.5, 50] #ratio, factor, radius\n",
    "config_4 = [0.05, 2, 50] #ratio, factor, radius\n",
    "config_5 = [0.05, 3, 50] #ratio, factor, radius\n",
    "\n",
    "for idx, config in enumerate([config_1, config_2, config_3, config_4, config_5]):\n",
    "    generator = UnivariateDataGenerator(stream_length=5000)\n",
    "    generator.point_contextual_outliers(*config)\n",
    "    \n",
    "    # save train\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-train.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.train)\n",
    "    \n",
    "    # save test\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-test.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.test)\n",
    "    \n",
    "    # save labels\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-labels.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34ee3c-8adc-4b69-9bad-334aa43779c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collective Global\n",
    "out_type = \"collective_global\"\n",
    "config_1 = [0.05, 50, 1.1] #ratio, radius, coef\n",
    "config_2 = [0.05, 50, 1.25] #ratio, radius, coef\n",
    "config_3 = [0.05, 50, 1.5] #ratio, radius, coef\n",
    "config_4 = [0.05, 50, 2] #ratio, radius, coef\n",
    "config_5 = [0.05, 50, 3] #ratio, radius, coef\n",
    "\n",
    "for idx, config in enumerate([config_1, config_2, config_3, config_4, config_5]):\n",
    "    *args, coef = config\n",
    "    generator = UnivariateDataGenerator(stream_length=5000)\n",
    "    generator.collective_global_outliers(*args, \"square\", coef=coef)\n",
    "    \n",
    "    # save train\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{coef}-train.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.train)\n",
    "    \n",
    "    # save test\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{coef}-test.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.test)\n",
    "    \n",
    "    # save labels\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{coef}-labels.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb5ddd-9060-4310-b6c9-c05b5ba053d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collective Trend\n",
    "out_type = \"collective_trend\"\n",
    "config_1 = [0.05, 0.01, 50] #ratio, factor, radius\n",
    "config_2 = [0.05, 0.02, 50] #ratio, factor, radius\n",
    "config_3 = [0.05, 0.03, 50] #ratio, factor, radius\n",
    "config_4 = [0.05, 0.04, 50] #ratio, factor, radius\n",
    "config_5 = [0.05, 0.05, 50] #ratio, factor, radius\n",
    "\n",
    "for idx, config in enumerate([config_1, config_2, config_3, config_4, config_5]):\n",
    "    generator = UnivariateDataGenerator(stream_length=5000)\n",
    "    generator.collective_trend_outliers(*config)\n",
    "    \n",
    "    # save train\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-train.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.train)\n",
    "    \n",
    "    # save test\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-test.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.test)\n",
    "    \n",
    "    # save labels\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-labels.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4784f76b-664e-45af-8ed6-4a0b51f2395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collective Seasonal\n",
    "out_type = \"collective_seasonal\"\n",
    "config_1 = [0.1, 1.1, 50] #ratio, factor, radius\n",
    "config_2 = [0.1, 1.25, 50] #ratio, factor, radius\n",
    "config_3 = [0.1, 1.5, 50] #ratio, factor, radius\n",
    "config_4 = [0.1, 2, 50] #ratio, factor, radius\n",
    "config_5 = [0.1, 3, 50] #ratio, factor, radius\n",
    "\n",
    "for idx, config in enumerate([config_1, config_2, config_3, config_4, config_5]):\n",
    "    generator = UnivariateDataGenerator(stream_length=5000)\n",
    "    generator.collective_seasonal_outliers(*config)\n",
    "    \n",
    "    # save train\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-train.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.train)\n",
    "    \n",
    "    # save test\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-test.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.test)\n",
    "    \n",
    "    # save labels\n",
    "    file_name = f\"{out_type}/{idx}-{out_type}-factor{config[1]}-labels.txt\"\n",
    "    np.savetxt(SAVE_DIR+file_name, generator.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c18388-89fa-4954-a693-e7d2ea535038",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Visualize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee03888d-fb73-460d-b742-0b5c1131ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH0 = \"./data/univar-synth/point_global/\"\n",
    "PATH1 = \"./data/univar-synth/point_contextual/\"\n",
    "PATH2 = \"./data/univar-synth/collective_global/\"\n",
    "PATH3 = \"./data/univar-synth/collective_trend/\"\n",
    "PATH4 = \"./data/univar-synth/collective_seasonal/\"\n",
    "PATHS = [PATH0, PATH1, PATH2, PATH3, PATH4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eaef81-87c2-4d5d-949b-c50e6047c63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    \n",
    "    for f in file_list:\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        fig, axes = plt.subplots(2)\n",
    "        axes[0].set_title(f)\n",
    "        axes[0].plot(test)\n",
    "        axes[1].plot(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24463bb6-4cc9-48f4-9b92-5781b967cc1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scoring Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a412f15e-5dd6-404d-b780-1c33747fc427",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreCounter:\n",
    "    def __init__(self):\n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.tn = 0\n",
    "        self.fn = 0\n",
    "        \n",
    "    def process(self, preds, labels):\n",
    "        preds = preds.copy()\n",
    "        labels = labels.copy()\n",
    "        ground_truth_ones = np.where(labels == 1)[0]\n",
    "        pred_ones = np.where(preds == 1)[0]\n",
    "        \n",
    "        ranges = self._consecutive(ground_truth_ones)\n",
    "        \n",
    "        tp, fp, tn, fn = 0, 0, 0, 0\n",
    "        \n",
    "        for r in ranges:\n",
    "            intersect = np.intersect1d(r, pred_ones, assume_unique=True)\n",
    "            if intersect.size != 0:\n",
    "                tp += r.size\n",
    "                preds[intersect] = 0\n",
    "                pred_ones = np.where(preds == 1)[0]\n",
    "            else:\n",
    "                fn += r.size\n",
    "            \n",
    "        fp += pred_ones.size\n",
    "        tn += preds.size - tp - fp - fn\n",
    "        \n",
    "        self.tp += tp\n",
    "        self.fp += fp\n",
    "        self.tn += tn\n",
    "        self.fn += fn\n",
    "        \n",
    "        \n",
    "        return\n",
    "        \n",
    "        \n",
    "    def _consecutive(self, data, stepsize=1):\n",
    "        return np.split(data, np.where(np.diff(data) != stepsize)[0]+1)\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def tpr(self):\n",
    "        return self.tp/(self.fn+self.tp)\n",
    "    \n",
    "    @property\n",
    "    def fpr(self):\n",
    "        return self.fp/(self.tn+self.fp)\n",
    "    \n",
    "    @property\n",
    "    def tnr(self):\n",
    "        return self.tn/(self.tn+self.fp)\n",
    "        \n",
    "    @property\n",
    "    def fnr(self):\n",
    "        return self.fn/(self.fn+self.tp)\n",
    "        \n",
    "    @property\n",
    "    def precision(self):\n",
    "        return self.tp/(self.tp+self.fp)\n",
    "    \n",
    "    @property\n",
    "    def recall(self):\n",
    "        return self.tp/(self.tp+self.fn)\n",
    "    \n",
    "    @property\n",
    "    def f1(self):\n",
    "        return (2*self.precision*self.recall)/(self.precision+self.recall)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568e7322-4b76-4857-9919-230823581a3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b146fb-ea3c-4ffd-8422-e003231a50f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc98de-a929-4f69-a5e8-ea5df3af6e75",
   "metadata": {},
   "source": [
    "### -- Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da67fb1-f805-446d-9603-5a48486389e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH0 = \"./data/univar-synth/point_global/\"\n",
    "PATH1 = \"./data/univar-synth/point_contextual/\"\n",
    "PATH2 = \"./data/univar-synth/collective_global/\"\n",
    "PATH3 = \"./data/univar-synth/collective_trend/\"\n",
    "PATH4 = \"./data/univar-synth/collective_seasonal/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f027dc8-57c7-4121-b46d-7a083c9a7d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = [PATH0, PATH1, PATH2, PATH3, PATH4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5821ed9e-7c6f-4c78-9491-6164955eadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"./results/univar-synth/untuned/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3766108-92a4-474a-8328-0ccc2849c49e",
   "metadata": {},
   "source": [
    "### Quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0885e7b-6ae4-44c7-b90b-b986d281fe7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quantile Model\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        window = 500\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = QuantileModel(window)\n",
    "        scores = model.get_scores(test_extend)[window:] \n",
    "        \n",
    "        save = SAVE_DIR+\"quantile/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"quantile/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", scores)\n",
    "        \n",
    "        scorer.process(scores, labels)\n",
    "       \n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acfef45-99e4-4bca-b4f3-71571b43976b",
   "metadata": {},
   "source": [
    "### MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebba815-e318-470a-8285-2392c6f4b9bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Moving Average Model\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        window = 50\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = MovingAverageModel(window)\n",
    "        scores = model.get_scores(test_extend)[window:] \n",
    "\n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.9)\n",
    "        \n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        save = SAVE_DIR+\"ma/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"ma/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "        \n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd12a5d-a709-44a0-a34d-b54349f7e417",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06feddc6-6f8b-421f-ad67-aedf29538e88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ARIMA\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = ARIMAModel(1,1,1)\n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[window:] \n",
    "\n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.9)\n",
    "        \n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        save = SAVE_DIR+\"arima/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"arima/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "        \n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd31eb5-d1b7-4edb-9328-f7f1c373b9ac",
   "metadata": {},
   "source": [
    "### IForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb5077-0bea-4fe7-abf1-96b734beba37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IsolationForest\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        model = IsolationForestModel()\n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test)\n",
    "            \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.9)\n",
    "       \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"iforest/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"iforest/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "       \n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddebc690-57d1-4a4c-84a6-45f396e1bd76",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d459aaf-bda0-44bc-a719-aff4ba0e81b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RegressionModel\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        window = 10\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = RegressionModel(window)\n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.90)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"regression/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"regression/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4e33c2-dcac-4e38-8f39-94ce4187e6db",
   "metadata": {},
   "source": [
    "### NBEATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd9f3f8-51a1-4759-ab93-b126bd4fc2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NBEATSModel\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        window = 100\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = NBEATSModel(window, use_gpu=True)\n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.90)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"nbeats/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"nbeats/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a59d3f-ecbb-43a3-9e09-e3ccfccac1ed",
   "metadata": {},
   "source": [
    "### NHiTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d60e31-4940-443a-9779-23c1d3931199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        window = 100\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = NHiTSModel(window, use_gpu=True)\n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.90)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"nhits/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"nhits/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4193f0-42c3-4547-b5d5-b63b9e79629c",
   "metadata": {},
   "source": [
    "### RNN(GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7781c98b-9659-40ec-a422-fec5c723e370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        window = 100\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = RNNModel(window, use_gpu=True, rnn_model=\"GRU\")\n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.90)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"rnn_gru/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"rnn_gru/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a47e38-bf4c-4e87-8b95-e47fc09a6198",
   "metadata": {},
   "source": [
    "### TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac05b28-b54f-4839-934a-45d157fa24b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        window = 100\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = TCNModel(window, use_gpu=True)\n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.90)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"tcn/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"tcn/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d59388f-b803-4b0f-bf6d-7092436b7cab",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3398f606-4124-458e-a45c-91af8f5f8a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        window = 100\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = TransformerModel(window, use_gpu=True)\n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, 1e-1, 0.90)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"transformer/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"transformer/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d877e11c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## F1 Tuned - 100% dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a158fb7d",
   "metadata": {},
   "source": [
    "### -- Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from one.models import *\n",
    "from one.utils import *\n",
    "from one.scorer.pot import *\n",
    "from numpy.lib.stride_tricks import sliding_window_view   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1243af",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH0 = \"./data/univar-synth/point_global/\"\n",
    "PATH1 = \"./data/univar-synth/point_contextual/\"\n",
    "PATH2 = \"./data/univar-synth/collective_global/\"\n",
    "PATH3 = \"./data/univar-synth/collective_trend/\"\n",
    "PATH4 = \"./data/univar-synth/collective_seasonal/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62953687",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = [PATH0, PATH1, PATH2, PATH3, PATH4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a5b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"./results/univar-synth/f1tuned-100pct/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace353be",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.FATAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bcb180",
   "metadata": {},
   "source": [
    "### Quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070298a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quantile Model\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            window = trial.suggest_int(\"window\", 100, 1000)\n",
    "            threshold = trial.suggest_float(\"threshold\", 0.95, 0.999)\n",
    "            \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "            model = QuantileModel(window)\n",
    "            scores = model.get_scores(test_extend)[window:] \n",
    "            \n",
    "\n",
    "            s.process(preds, labels)\n",
    "       \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            return s.f1\n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=150)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        threshold = study.best_params[\"threshold\"]\n",
    "        model = QuantileModel(window, threshold)\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        \n",
    "        scores = model.get_scores(test_extend)[window:] \n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"quantile/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"quantile/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", scores)\n",
    "\n",
    "        scorer.process(scores, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66ecbf",
   "metadata": {},
   "source": [
    "### MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295cf97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MA Model \n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "            model = MovingAverageModel(window)\n",
    "            scores = np.abs(model.get_scores(test_extend)[window:])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            return s.f1\n",
    "            \n",
    "       \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=150)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        model = MovingAverageModel(window)\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        \n",
    "        scores = np.abs(model.get_scores(test_extend)[window:] )\n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"ma/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"ma/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40acc764",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b27b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA Model \n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            p = trial.suggest_int(\"p\", 1, 20)\n",
    "            d = trial.suggest_int(\"d\", 0, 3)\n",
    "            q = trial.suggest_int(\"q\", 0, 20)\n",
    "            q_risk = trial.suggest_float(\"q_risk\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    " \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "                \n",
    "            model = ARIMAModel(p, d, q)\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend))\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q_risk, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "       \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=20)\n",
    "       \n",
    "        p = study.best_params[\"p\"]\n",
    "        d = study.best_params[\"d\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        q_risk = study.best_params[\"q_risk\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "        model = ARIMAModel(p, d, q)\n",
    "        model.fit(train)\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        scores = np.abs(model.get_scores(test_extend))\n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q_risk, contam)\n",
    "        \n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"arima/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"arima/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa95cdb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### IForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2439bb99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IForest Model \n",
    "import warnings\n",
    "warnings.filterwarnings('error')\n",
    "\n",
    "\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "                \n",
    "            model = IsolationForestModel()\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test))\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            \n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "            \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=150)\n",
    "       \n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        model = IsolationForestModel()\n",
    "        model.fit(train)\n",
    "        scores = np.abs(model.get_scores(test))\n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"iforest/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"iforest/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9765ec1b",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f08b776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Regression Model \n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            lags = trial.suggest_int(\"lags\", 1, 5)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    " \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "                \n",
    "            model = RegressionModel(window, n_steps, lags)\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "       \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=50)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        lags = study.best_params[\"lags\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "        model = RegressionModel(window,n_steps, lags)\n",
    "        model.fit(train)\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        scores = np.abs(model.get_scores(test_extend)[0])\n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"regression/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"regression/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cef4025",
   "metadata": {},
   "source": [
    "### NBEATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8866c5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# NBEATSModel\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "#             params = {\n",
    "#              \"num_blocks\": trial.suggest_int(\"num_blocks\", 1, 2),\n",
    "#              \"num_stacks\": trial.suggest_int(\"num_stacks\", 2, 32),\n",
    "#              \"num_layers\": trial.suggest_int(\"num_layers\", 1, 16),\n",
    "#              \"layer_widths\": trial.suggest_int(\"layer_widths\", 128, 512),\n",
    "#              \"expansion_coefficient_dim\": trial.suggest_int(\n",
    "#                  \"expansion_coefficient_dim\", 1, 10\n",
    "#              ),\n",
    "#             } \n",
    " \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "                \n",
    "            model = NBEATSModel(window, n_steps, use_gpu=True)            \n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "#         params = {\n",
    "#          \"num_blocks\": study.best_params[\"num_blocks\"],\n",
    "#          \"num_stacks\": study.best_params[\"num_stacks\"],\n",
    "#          \"num_layers\": study.best_params[\"num_layers\"],\n",
    "#          \"layer_widths\": study.best_params[\"layer_widths\"],\n",
    "#          \"expansion_coefficient_dim\": study.best_params[\"expansion_coefficient_dim\"],\n",
    "#         } \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = NBEATSModel(window, n_steps, use_gpu=True)\n",
    "#         model.params = params\n",
    "#         model._init_model(**model.params)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"nbeats/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"nbeats/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"nbeats/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99be305c",
   "metadata": {},
   "source": [
    "### NHiTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d803257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture #supress output\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "                \n",
    "            model = NHiTSModel(window, n_steps, use_gpu=True)\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = NHiTSModel(window, n_steps, use_gpu=True)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"nhits/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"nhits/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"nhits/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52cd792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in PATHS:\n",
    "#     scorer = ScoreCounter()\n",
    "#     file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "#     for f in file_list:\n",
    "#         labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "#         preds = np.loadtxt(SAVE_DIR+\"nhits/\"+f+\"-preds.txt\")\n",
    "#         scorer.process(preds, labels)\n",
    "        \n",
    "#     print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb85e191",
   "metadata": {},
   "source": [
    "### RNN(GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055223b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#supress output\n",
    "\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "#             params = {\n",
    "#              \"hidden_dim\": trial.suggest_int(\"hidden_dim\", 10, 256),\n",
    "#              \"n_rnn_layers\": trial.suggest_int(\"n_rnn_layers\", 1, 64),\n",
    "#              \"dropout\": trial.suggest_float(\"dropout\", 0.0, 0.3),\n",
    "#              } \n",
    " \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "                \n",
    "            model = RNNModel(window, n_steps, rnn_model=\"GRU\")\n",
    "#             model.params = params\n",
    "#             model._init_model(**model.params)\n",
    "            \n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "#         params = {\n",
    "#          \"hidden_dim\": study.best_params[\"hidden_dim\"],\n",
    "#          \"n_rnn_layers\": study.best_params[\"n_rnn_layers\"],\n",
    "#          \"dropout\": study.best_params[\"dropout\"],\n",
    "#         } \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = RNNModel(window, n_steps, use_gpu=True, rnn_model=\"GRU\")\n",
    "#         model.params = params\n",
    "#         model._init_model(**model.params)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"rnn_gru/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"rnn_gru/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"rnn_gru/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63b4567",
   "metadata": {},
   "source": [
    "### TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0173ab58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#supress output\n",
    "# %%capture\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "#             params = {\n",
    "#              \"kernel_size\": trial.suggest_int(\n",
    "#                  \"kernel_size\", 2, min(32, window - 1)\n",
    "#              ),\n",
    "#              \"num_filters\": trial.suggest_int(\"num_filters\", 2, 8),\n",
    "#              \"weight_norm\": trial.suggest_categorical(\"weight_norm\", [True, False]),\n",
    "#              \"dilation_base\": trial.suggest_int(\"dilation_base\", 1, 4),\n",
    "#              \"dropout\": trial.suggest_float(\"dropout\", 0.0, 0.3),\n",
    "#              }\n",
    "                \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "            \n",
    "            model = TCNModel(window, n_steps, use_gpu=True)\n",
    "            #model.params = params\n",
    "            #model._init_model(**model.params)\n",
    "            \n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "#         params = {\n",
    "#          \"kernel_size\": study.best_params[\"kernel_size\"],\n",
    "#          \"num_filters\": study.best_params[\"num_filters\"],\n",
    "#          \"dilation_base\": study.best_params[\"dilation_base\"],\n",
    "#          \"dropout\": study.best_params[\"dropout\"],\n",
    "#         } \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = TCNModel(window, n_steps, use_gpu=True)\n",
    "#         model.params = params\n",
    "#         model._init_model(**model.params)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"tcn/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"tcn/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"tcn/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d30be85",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cc5af1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "            test_extend = np.concatenate((train[-window:], test))\n",
    "                \n",
    "            model = TransformerModel(window, n_steps, use_gpu=True)\n",
    "            %%capture #supress output\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = TransformerModel(window, n_steps, use_gpu=True)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"transformer/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"transformer/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"transformer/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40343d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in PATHS:\n",
    "    scorer = ScoreCounter()\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    for f in file_list:\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        preds = np.loadtxt(SAVE_DIR+\"transformer/\"+f+\"-preds.txt\")\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c8acc2-00db-4d94-bf16-a63d22043a7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## F1 Tuned - 50% dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65a3c1e-7a7f-4cf2-a2bb-e596baa6f8d3",
   "metadata": {},
   "source": [
    "### -- Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0fb3f4-9acd-4b99-94a9-9068c8ef2601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from one.models import *\n",
    "from one.utils import *\n",
    "from one.scorer.pot import *\n",
    "from numpy.lib.stride_tricks import sliding_window_view   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b29d3-c4a0-4d09-83f0-904dce2ed7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH0 = \"./data/univar-synth/point_global/\"\n",
    "PATH1 = \"./data/univar-synth/point_contextual/\"\n",
    "PATH2 = \"./data/univar-synth/collective_global/\"\n",
    "PATH3 = \"./data/univar-synth/collective_trend/\"\n",
    "PATH4 = \"./data/univar-synth/collective_seasonal/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7509bfcb-ac94-4ff9-a492-ae5609d53aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = [PATH0, PATH1, PATH2, PATH3, PATH4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986822e6-c5e0-482f-b200-27f4fa17ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"./results/univar-synth/f1tuned-50pct/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd02e3-2b7d-41da-8ca6-f8ca5dacd656",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.FATAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d5eea4-7ba6-41d0-8e29-a8b0a1402de3",
   "metadata": {},
   "source": [
    "### Quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b615cff-4baf-43cf-9e71-f07a21b715fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quantile Model\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            window = trial.suggest_int(\"window\", 100, 1000)\n",
    "            threshold = trial.suggest_float(\"threshold\", 0.95, 0.999)\n",
    "            \n",
    "            test_extend = np.concatenate((train[-window:], tune_data))\n",
    "            model = QuantileModel(window)\n",
    "            scores = model.get_scores(test_extend)[window:] \n",
    "            \n",
    "\n",
    "            s.process(preds, tune_labels)\n",
    "       \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            return s.f1\n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=150)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        threshold = study.best_params[\"threshold\"]\n",
    "        model = QuantileModel(window, threshold)\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        \n",
    "        scores = model.get_scores(test_extend)[window:] \n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"quantile/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"quantile/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", scores)\n",
    "\n",
    "        scorer.process(scores, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35090c0b-683d-41f0-bcac-0955143aabe2",
   "metadata": {},
   "source": [
    "### MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c514753-fcd2-4983-bac6-69daabf7610f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MA Model \n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "            test_extend = np.concatenate((train[-window:], tune_data))\n",
    "            model = MovingAverageModel(window)\n",
    "            scores = np.abs(model.get_scores(test_extend)[window:])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            return s.f1\n",
    "            \n",
    "       \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=150)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        model = MovingAverageModel(window)\n",
    "        \n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        \n",
    "        scores = np.abs(model.get_scores(test_extend)[window:] )\n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"ma/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"ma/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c1fc97-dd42-4b80-af36-4d7965d64c21",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cecc21-3402-4857-b815-fcd5bbc8a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA Model \n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "\n",
    "\n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            p = trial.suggest_int(\"p\", 1, 20)\n",
    "            d = trial.suggest_int(\"d\", 0, 3)\n",
    "            q = trial.suggest_int(\"q\", 0, 20)\n",
    "            q_risk = trial.suggest_float(\"q_risk\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    " \n",
    "            test_extend = np.concatenate((train[-window:], tune_data))\n",
    "                \n",
    "            model = ARIMAModel(p, d, q)\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend))\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q_risk, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "       \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=20)\n",
    "       \n",
    "        p = study.best_params[\"p\"]\n",
    "        d = study.best_params[\"d\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        q_risk = study.best_params[\"q_risk\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "        model = ARIMAModel(p, d, q)\n",
    "        model.fit(train)\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        scores = np.abs(model.get_scores(test_extend))\n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q_risk, contam)\n",
    "        \n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"arima/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"arima/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6152b849-782e-45ae-8793-b36e8c17b60c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### IForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec0b52a-f461-476e-a906-a18e5e45155f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IForest Model \n",
    "import warnings\n",
    "warnings.filterwarnings('error')\n",
    "\n",
    "\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "\n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "\n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "                \n",
    "            model = IsolationForestModel()\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(tune_data))\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            \n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "            \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=150)\n",
    "       \n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        model = IsolationForestModel()\n",
    "        model.fit(train)\n",
    "        scores = np.abs(model.get_scores(test))\n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"iforest/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"iforest/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dce11d2-6d48-49b0-9b45-407e5e9ee150",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b2c35c-0a5b-460c-9106-972e95ba8e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Regression Model \n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "\n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            lags = trial.suggest_int(\"lags\", 1, 5)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    " \n",
    "            test_extend = np.concatenate((train[-window:], tune_data))\n",
    "                \n",
    "            model = RegressionModel(window, n_steps, lags)\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "       \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=50)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        lags = study.best_params[\"lags\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "        model = RegressionModel(window,n_steps, lags)\n",
    "        model.fit(train)\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        scores = np.abs(model.get_scores(test_extend)[0])\n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"regression/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"regression/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores)\n",
    "        np.savetxt(save+\"-preds.txt\", preds)\n",
    "\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a695b8-f6e2-4349-9b4a-1a104ab927d0",
   "metadata": {},
   "source": [
    "### NBEATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103a7312-9fa6-4e97-9814-9411e1c669ac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# NBEATSModel\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "#             params = {\n",
    "#              \"num_blocks\": trial.suggest_int(\"num_blocks\", 1, 2),\n",
    "#              \"num_stacks\": trial.suggest_int(\"num_stacks\", 2, 32),\n",
    "#              \"num_layers\": trial.suggest_int(\"num_layers\", 1, 16),\n",
    "#              \"layer_widths\": trial.suggest_int(\"layer_widths\", 128, 512),\n",
    "#              \"expansion_coefficient_dim\": trial.suggest_int(\n",
    "#                  \"expansion_coefficient_dim\", 1, 10\n",
    "#              ),\n",
    "#             } \n",
    " \n",
    "            test_extend = np.concatenate((train[-window:], tune_data))\n",
    "                \n",
    "            model = NBEATSModel(window, n_steps, use_gpu=True)            \n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "#         params = {\n",
    "#          \"num_blocks\": study.best_params[\"num_blocks\"],\n",
    "#          \"num_stacks\": study.best_params[\"num_stacks\"],\n",
    "#          \"num_layers\": study.best_params[\"num_layers\"],\n",
    "#          \"layer_widths\": study.best_params[\"layer_widths\"],\n",
    "#          \"expansion_coefficient_dim\": study.best_params[\"expansion_coefficient_dim\"],\n",
    "#         } \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = NBEATSModel(window, n_steps, use_gpu=True)\n",
    "#         model.params = params\n",
    "#         model._init_model(**model.params)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"nbeats/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"nbeats/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"nbeats/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d3dd36-c4cd-42b3-abf5-c8f4aaf23b92",
   "metadata": {},
   "source": [
    "### NHiTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3278ef0-881b-446b-afa5-b148345df8c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#supress output\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        \n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "\n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "            test_extend = np.concatenate((train[-window:], tune_data))\n",
    "                \n",
    "            model = NHiTSModel(window, n_steps, use_gpu=True)\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = NHiTSModel(window, n_steps, use_gpu=True)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"nhits/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"nhits/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"nhits/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d84b0d1-d9d5-4e95-b35c-b3d8cd53e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in PATHS:\n",
    "#     scorer = ScoreCounter()\n",
    "#     file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "#     for f in file_list:\n",
    "#         labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "#         preds = np.loadtxt(SAVE_DIR+\"nhits/\"+f+\"-preds.txt\")\n",
    "#         scorer.process(preds, labels)\n",
    "        \n",
    "#     print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d6373-721d-4087-894d-2eed122a8d98",
   "metadata": {},
   "source": [
    "### RNN(GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa60b5-0d53-45a9-b0e2-fb7d85434552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#supress output\n",
    "\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "#             params = {\n",
    "#              \"hidden_dim\": trial.suggest_int(\"hidden_dim\", 10, 256),\n",
    "#              \"n_rnn_layers\": trial.suggest_int(\"n_rnn_layers\", 1, 64),\n",
    "#              \"dropout\": trial.suggest_float(\"dropout\", 0.0, 0.3),\n",
    "#              } \n",
    " \n",
    "            test_extend = np.concatenate((train[-window:], tune_data))\n",
    "                \n",
    "            model = RNNModel(window, n_steps, rnn_model=\"GRU\")\n",
    "#             model.params = params\n",
    "#             model._init_model(**model.params)\n",
    "            \n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "#         params = {\n",
    "#          \"hidden_dim\": study.best_params[\"hidden_dim\"],\n",
    "#          \"n_rnn_layers\": study.best_params[\"n_rnn_layers\"],\n",
    "#          \"dropout\": study.best_params[\"dropout\"],\n",
    "#         } \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = RNNModel(window, n_steps, use_gpu=True, rnn_model=\"GRU\")\n",
    "#         model.params = params\n",
    "#         model._init_model(**model.params)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"rnn_gru/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"rnn_gru/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"rnn_gru/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b1b76e-9ba3-47ef-8f52-abe62d222746",
   "metadata": {},
   "source": [
    "### TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476829ed-51d3-4414-80a2-b7e1f1ae93d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 9, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "#             params = {\n",
    "#              \"kernel_size\": trial.suggest_int(\n",
    "#                  \"kernel_size\", 2, min(32, window - 1)\n",
    "#              ),\n",
    "#              \"num_filters\": trial.suggest_int(\"num_filters\", 2, 8),\n",
    "#              \"weight_norm\": trial.suggest_categorical(\"weight_norm\", [True, False]),\n",
    "#              \"dilation_base\": trial.suggest_int(\"dilation_base\", 1, 4),\n",
    "#              \"dropout\": trial.suggest_float(\"dropout\", 0.0, 0.3),\n",
    "#              }\n",
    "                \n",
    "            test_extend = np.concatenate((train[-window:], tune_data))\n",
    "            \n",
    "            model = TCNModel(window, n_steps, use_gpu=True)\n",
    "            #model.params = params\n",
    "            #model._init_model(**model.params)\n",
    "            \n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "#         params = {\n",
    "#          \"kernel_size\": study.best_params[\"kernel_size\"],\n",
    "#          \"num_filters\": study.best_params[\"num_filters\"],\n",
    "#          \"dilation_base\": study.best_params[\"dilation_base\"],\n",
    "#          \"dropout\": study.best_params[\"dropout\"],\n",
    "#         } \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = TCNModel(window, n_steps, use_gpu=True)\n",
    "#         model.params = params\n",
    "#         model._init_model(**model.params)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"tcn/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"tcn/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"tcn/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baa0482-d0bd-4718-98e0-0eb6f9c9678e",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb8a6a3-0cba-403b-b175-2e56002696e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "for path in PATHS:\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    scorer = ScoreCounter()\n",
    "    for f in file_list:\n",
    "        train = np.loadtxt(path+f+\"-train.txt\")\n",
    "        test = np.loadtxt(path+f+\"-test.txt\")\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        \n",
    "        n_tune = labels.size // 2\n",
    "        tune_data, tune_labels = test[:n_tune], labels[:n_tune]\n",
    "\n",
    "        \n",
    "        def objective(trial):\n",
    "            s = ScoreCounter()\n",
    "            \n",
    "            window = trial.suggest_int(\"window\", 10, 150)\n",
    "            n_steps = trial.suggest_int(\"n_steps\", 1, 10, log=True)\n",
    "            q = trial.suggest_float(\"q\", 1e-5, 1e-1, log=True)\n",
    "            contam = trial.suggest_float(\"contam\", 0.90, 0.999)\n",
    "            \n",
    "            test_extend = np.concatenate((train[-window:], tune_data))\n",
    "                \n",
    "            model = TransformerModel(window, n_steps, use_gpu=True)\n",
    "\n",
    "            model.fit(train)\n",
    "            scores = np.abs(model.get_scores(test_extend)[0])\n",
    "\n",
    "            # Get threshold (Not needed for Quantile)\n",
    "            thres = pot(scores, q, contam)\n",
    "            preds = scores.copy()\n",
    "            preds[preds <= thres] = 0\n",
    "            preds[preds > thres] = 1\n",
    " \n",
    "            s.process(preds, tune_labels)\n",
    "        \n",
    "            if s.tp == 0 and s.fp == 0: return -1\n",
    "            if s.tp == 0 and s.fn == 0: return -1\n",
    "\n",
    "            if s.precision == 0 and s.recall == 0: return -1\n",
    "            if np.isnan(s.f1): return -1\n",
    "            return s.f1\n",
    " \n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=35)\n",
    "       \n",
    "        window = study.best_params[\"window\"]\n",
    "        n_steps = study.best_params[\"n_steps\"]\n",
    "        q = study.best_params[\"q\"]\n",
    "        contam = study.best_params[\"contam\"]\n",
    "        \n",
    "\n",
    "        test_extend = np.concatenate((train[-window:], test))\n",
    "        model = TransformerModel(window, n_steps, use_gpu=True)\n",
    " \n",
    "        model.fit(train)\n",
    "        scores = model.get_scores(test_extend)[0]\n",
    "        \n",
    "        \n",
    "        # Get threshold (Not needed for Quantile)\n",
    "        thres = pot(scores, q, contam)\n",
    "        \n",
    "        # Get predictions from threshold\n",
    "        preds = scores.copy()\n",
    "        preds[preds <= thres] = 0\n",
    "        preds[preds > thres] = 1\n",
    "        \n",
    "        # Save results\n",
    "        save = SAVE_DIR+\"transformer/\"+f\n",
    "        os.makedirs(SAVE_DIR+\"transformer/\", exist_ok=True)\n",
    "        np.savetxt(save+\"-scores.txt\", scores, header=study.best_params.__str__())\n",
    "        np.savetxt(save+\"-preds.txt\", preds, header=study.best_params.__str__())\n",
    "\n",
    "        scorer.process(preds, labels)\n",
    "\n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n",
    "    with open(SAVE_DIR+\"transformer/summary.txt\", 'a+') as summary:\n",
    "        summary.write(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c051f-6787-4d28-baea-d1849b63a651",
   "metadata": {},
   "source": [
    "## Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c6679-4a62-4f35-b44e-65a9f8a6358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"regression\"\n",
    "for path in PATHS:\n",
    "    scorer = ScoreCounter()\n",
    "    file_list = [\"-\".join(f.split(\"-\")[:-1]) for f in get_files_from_path(path) if \"train\" in f]\n",
    "    for f in file_list:\n",
    "        labels = np.loadtxt(path+f+\"-labels.txt\")\n",
    "        preds = np.loadtxt(SAVE_DIR+f\"{transformer}/\"+f+\"-preds.txt\")\n",
    "        scorer.process(preds, labels)\n",
    "        \n",
    "    print(f\"{scorer.tp}, {scorer.fp}, {scorer.tn}, {scorer.fn}, {scorer.tpr}, {scorer.fpr}, {scorer.tnr}, {scorer.fnr}, {scorer.precision}, {scorer.recall}, {scorer.f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d810f46-7a04-4280-866c-4b4e7b680309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
